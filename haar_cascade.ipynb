{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpetros11111/Complete_ComputerVisiom_Krishn/blob/main/haar_cascade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yiCqFCHqQgk"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z129c71BqQgl"
      },
      "outputs": [],
      "source": [
        "# Face Detection\n",
        "\n",
        "cam = cv2.VideoCapture(0)\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "while True:\n",
        "    ret, frame = cam.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame\")\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "\n",
        "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "        cv2.putText(frame, \"Face Detected\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imshow('Camera', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Haar-cascade based face detection\n",
        "This code uses the OpenCV (cv2) library in Python to perform real-time face detection using your computer's camera.\n",
        "\n",
        "----\n",
        "----\n",
        "#1. Initialization:\n",
        "\n",
        "##cam = cv2.VideoCapture(0):\n",
        "This line initializes the camera.\n",
        "\n",
        "0 usually refers to the default webcam.\n",
        "\n",
        "##face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'):\n",
        "\n",
        "This line loads a pre-trained Haar Cascade classifier for frontal face detection.\n",
        "\n",
        "Haar Cascades are a machine learning-based approach for object detection.\n",
        "\n",
        "--------------\n",
        "#2. Main Loop:\n",
        "\n",
        "##while True::\n",
        "This starts an infinite loop that runs continuously until you press the 'q' key.\n",
        "\n",
        "##ret, frame = cam.read():\n",
        "This line reads a frame from the camera. ret is a boolean indicating if the frame was read successfully, and frame is the actual image frame.\n",
        "\n",
        "##if not ret: ... break:\n",
        "If the frame wasn't read successfully, it prints an error message and breaks the loop.\n",
        "\n",
        "##gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY):\n",
        "This line converts the frame to grayscale. Face detection often works better on grayscale images.\n",
        "\n",
        "-------------\n",
        "#3. Face Detection:\n",
        "\n",
        "##faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5):\n",
        "This is the core face detection step.\n",
        "\n",
        "It uses the loaded classifier to detect faces in the grayscale image.\n",
        "\n",
        "##face_cascade:\n",
        "This is an object of the cv2.\n",
        "\n",
        "CascadeClassifier class.\n",
        "\n",
        "It holds the pre-trained Haar Cascade classifier that you loaded earlier.\n",
        "\n",
        "This classifier has been trained to recognize patterns associated with frontal faces.\n",
        "\n",
        "##detectMultiScale:\n",
        "This is a method of the cv2.\n",
        "\n",
        "##CascadeClassifier class.\n",
        "It's the function that actually performs the face detection.\n",
        "\n",
        "It takes the image as input and tries to find regions within the image that match the patterns of a frontal face.\n",
        "\n",
        "##How it works:\n",
        "The detectMultiScale function uses a sliding window approach.\n",
        "\n",
        "It essentially moves a window of varying sizes across the image, looking for areas that resemble a face according to the Haar Cascade classifier.\n",
        "\n",
        "If it finds a region that scores high enough (meaning it closely matches the face pattern), it considers that region as a potential face.\n",
        "\n",
        "##Output:\n",
        "The detectMultiScale function returns a list of rectangles.\n",
        "\n",
        "Each rectangle represents a detected face in the image.\n",
        "\n",
        "The rectangle is defined by four values: (x, y, w, h), where (x, y) represents the top-left corner of the rectangle, and w and h represent the width and height of the rectangle, respectively.\n",
        "\n",
        "##Parameters:\n",
        "The detectMultiScale function takes several optional parameters that you can use to fine-tune the detection process.\n",
        "\n",
        "These include:\n",
        "\n",
        "##scaleFactor:\n",
        "Controls how much the image size is reduced at each image scale.\n",
        "\n",
        "A smaller scale factor increases the detection accuracy but also increases the processing time.\n",
        "\n",
        "##minNeighbors:\n",
        "Specifies how many neighbors each candidate rectangle should have to retain it.\n",
        "\n",
        "A higher value reduces the number of false positives but might miss some faces.\n",
        "\n",
        "##minSize:\n",
        "Specifies the minimum possible object size. Objects smaller than that are ignored.\n",
        "\n",
        "##maxSize:\n",
        "Specifies the maximum possible object size. Objects larger than that are ignored.\n",
        "\n",
        "##In summary,\n",
        "face_cascade.detectMultiScale is the heart of the face detection process in this code.\n",
        "\n",
        "It takes the image and the pre-trained classifier as input, scans the image for face-like regions, and returns a list of rectangles representing the detected faces.\n",
        "\n",
        "##scaleFactor:\n",
        "This parameter controls how the image size is reduced at each image scale.\n",
        "\n",
        "A smaller scale factor increases the detection accuracy but also increases the processing time.\n",
        "\n",
        "##minNeighbors:\n",
        "This parameter specifies how many neighbors each candidate rectangle should have to retain it.\n",
        "\n",
        "A higher value reduces the number of false positives but might miss some faces.\n",
        "\n",
        "----------------\n",
        "#4. Drawing Rectangles and Labels:\n",
        "\n",
        "##for (x,y,w,h) in faces::\n",
        "This loop iterates through all the detected faces.\n",
        "\n",
        "##cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2):\n",
        "This line draws a blue rectangle around the detected face on the original color frame.\n",
        "\n",
        "##cv2.putText(frame, \"Face Detected\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA):\n",
        "\n",
        "This line adds the text \"Face Detected\" above the rectangle.\n",
        "\n",
        "----------------------\n",
        "#5. Displaying the Output:\n",
        "\n",
        "##cv2.imshow('Camera', frame):\n",
        "This line displays the frame with the detected faces in a window titled \"Camera\".\n",
        "\n",
        "##if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "\n",
        "##break:\n",
        "This line waits for a key press for 1 millisecond.\n",
        "\n",
        "If the 'q' key is pressed, it breaks the loop.\n",
        "\n",
        "---------------------\n",
        "#6. Cleanup:\n",
        "\n",
        "##cam.release():\n",
        "This line releases the camera.\n",
        "\n",
        "##cv2.destroyAllWindows():\n",
        "This line closes all OpenCV windows.\n",
        "\n",
        "----------------------------\n",
        "#In essence,\n",
        "this code continuously captures frames from your camera, detects faces in each frame, and draws rectangles around the detected faces, updating the display in real-time."
      ],
      "metadata": {
        "id": "4zj3qYu_q_OD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5_E32BLqQgm"
      },
      "outputs": [],
      "source": [
        "# face + eye + mouth\n",
        "\n",
        "cam = cv2.VideoCapture(0)\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "mouth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
        "\n",
        "while True:\n",
        "    ret, frame = cam.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame\")\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "\n",
        "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        cv2.putText(frame, \"Face Detected\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
        "\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = frame[y:y+h, x:x+w]\n",
        "\n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.3, minNeighbors=5)\n",
        "        mouths = mouth_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)\n",
        "\n",
        "        for (ex,ey, ew, eh) in eyes:\n",
        "            cv2.rectangle(frame, (x+ex,y+ey), (x+ex+ew, y+ey+eh), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, \"Eye\", (x+ex,(y+ey) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
        "\n",
        "        for (mx,my, mw, mh) in mouths:\n",
        "            cv2.rectangle(frame, (x+mx,y+my), (x+mx+mw, y+my+mh), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, \"Mouth\", (x+mx,(y+my) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "    cv2.imshow('Camera', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detects faces, eyes, and mouths in real-time\n",
        "\n",
        "-------------\n",
        "----------\n",
        "#1. Initialization:\n",
        "\n",
        "Similar to before, the code initializes the camera using cv2.VideoCapture(0).\n",
        "\n",
        "It loads three Haar Cascade classifiers:\n",
        "\n",
        "face_cascade: for face detection.\n",
        "\n",
        "eye_cascade: for eye detection.\n",
        "\n",
        "mouth_cascade: for mouth detection.\n",
        "\n",
        "-----------------\n",
        "#2. Main Loop and Face Detection:\n",
        "\n",
        "The code enters a while True loop, continuously reading frames from the camera.\n",
        "\n",
        "It converts each frame to grayscale using cv2.cvtColor.\n",
        "\n",
        "It detects faces in the grayscale image using face_cascade.detectMultiScale.\n",
        "\n",
        "-------------------------\n",
        "#3. Region of Interest (ROI) and Eye/Mouth Detection:\n",
        "\n",
        "For each detected face, it defines a region of interest (ROI) within the frame using array slicing:\n",
        "roi_gray: grayscale ROI containing the face.\n",
        "roi_color: color ROI containing the face.\n",
        "It then uses eye_cascade.detectMultiScale and mouth_cascade.detectMultiScale to detect eyes and mouths within the ROI, respectively.\n",
        "\n",
        "------------------------\n",
        "#4. Drawing Rectangles and Labels:\n",
        "\n",
        "It draws rectangles and labels for the detected faces, eyes, and mouths using cv2.rectangle and cv2.putText.\n",
        "\n",
        "Notice that for eyes and mouths, the coordinates are adjusted relative to the face's position (x+ex, y+ey, etc.).\n",
        "\n",
        "---------------------\n",
        "#5. Display and Cleanup:\n",
        "\n",
        "The code displays the frame with the detected features using cv2.imshow.\n",
        "\n",
        "It breaks the loop when the 'q' key is pressed.\n",
        "\n",
        "Finally, it releases the camera and closes all windows using cam.release() and cv2.destroyAllWindows().\n",
        "\n",
        "--------------------\n",
        "#In essence,\n",
        "this code detects faces, eyes, and mouths in real-time video using Haar Cascade classifiers.\n",
        "\n",
        "By defining ROIs around the detected faces, it focuses the eye and mouth detection on relevant areas, improving efficiency and accuracy."
      ],
      "metadata": {
        "id": "u6VEu3_u22UM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms8scNMwqQgn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "KNCVU",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}